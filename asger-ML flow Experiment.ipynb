{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "## NOTE: Optionally, you can use the public tracking server.  Do not use it for data you cannot afford to lose. See note in assignment text. If you leave this line as a comment, mlflow will save the runs to your local filesystem.\n",
    "\n",
    "# mlflow.set_tracking_uri(\"http://training.itu.dk:5000/\")\n",
    "\n",
    "# TODO: Set the experiment name\n",
    "#mlflow.set_experiment(\"<acsc> - <Wind experiment>\")\n",
    "\n",
    "# Import some of the sklearn modules you are likely to use.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn . preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import OneHotEncoder # changing the string data to categorical data like changing Direction to numbers\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn . neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR MAE 4.5859195172585165\n",
      "LR MSE 37.431953512813564\n",
      "KNN MAE 4.215826790567686\n",
      "KNN MSE 32.611658025493625\n",
      "RF MAE 4.154590913265693\n",
      "RF MSE 32.79856125127577\n",
      "DCT MAE 4.366211995242817\n",
      "DCT MSE 36.4444946082504\n",
      "LR MAE 4.495093495178856\n",
      "LR MSE 35.559756186252926\n",
      "KNN MAE 4.164651998253275\n",
      "KNN MSE 31.899260039392345\n",
      "RF MAE 3.8750160532547837\n",
      "RF MSE 27.786372596851788\n",
      "DCT MAE 3.875695135477163\n",
      "DCT MSE 27.787722417139797\n"
     ]
    }
   ],
   "source": [
    "# Start a run\n",
    "# TODO: Set a descriptive name. This is optional, but makes it easier to keep track of your runs.\n",
    "df = pd.read_json(r\"dataset.json\", orient=\"split\")\n",
    "df = df.drop(columns=['ANM', 'Non-ANM','Lead_hours'])\n",
    "df = df.ffill().bfill()\n",
    "#df = df.dropna()\n",
    "X = df[[\"Speed\",\"Direction\"]]\n",
    "y = df[\"Total\"]\n",
    "count = 0 \n",
    "while True:\n",
    "    if count == 2:\n",
    "        break\n",
    "    if count ==0:\n",
    "        X = df[[\"Speed\",\"Direction\"]]\n",
    "    else:\n",
    "        X = df[[\"Speed\"]]\n",
    "    count += 1\n",
    "    mlflow.set_experiment(f\"Wind experiment_X{count}\")\n",
    "    with mlflow.start_run(run_name=\"Run_1\"):\n",
    "        mlflow.log_artifact(\"dataset.json\")\n",
    "        categorical_cols = [cname for cname in X.columns if X[cname].nunique() < 20 and \n",
    "                            X[cname].dtype == \"object\"]\n",
    "\n",
    "        # Select numerical columns\n",
    "        numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "        # Keep selected columns only\n",
    "        my_cols = categorical_cols + numerical_cols\n",
    "\n",
    "        # Preprocessing for numerical data\n",
    "        numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "        # Preprocessing for categorical data\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        # Bundle preprocessing for numerical and categorical data\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numerical_transformer, numerical_cols),\n",
    "                ('cat', categorical_transformer, categorical_cols),\n",
    "            ])\n",
    "\n",
    "        #model = RandomForestRegressor(n_estimators=100, random_state=15)\n",
    "        for model_tuple in [(\"LR\", LinearRegression()), \n",
    "                            (\"KNN\", KNeighborsRegressor()),\n",
    "                            (\"RF\", RandomForestRegressor()),\n",
    "                           (\"DCT\", DecisionTreeRegressor())\n",
    "                        ]: ## add Decision tree as well, KNN\n",
    "            #model = LinearRegression()\n",
    "            model = model_tuple[1]\n",
    "            from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "            # Bundle preprocessing and modeling code in a pipeline\n",
    "            my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                      ('model', model)\n",
    "                                     ])\n",
    "            #     my_pipeline = Pipeline([\n",
    "            #         # TODO: You can start with your pipeline from assignment 1\n",
    "            #     ])\n",
    "\n",
    "            # TODO: Currently the only metric is MAE. You should add more. What other metrics could you use? Why?\n",
    "            metrics = [\n",
    "                (\"MAE\", mean_absolute_error, []),\n",
    "                (\"MSE\", mean_squared_error, [])# NME as well as RMSE\n",
    "            ]\n",
    "\n",
    "\n",
    "            number_of_splits = 5\n",
    "            #TODO: Log your parameters. What parameters are important to log?\n",
    "            #HINT: You can get access to the transformers in your pipeline using `pipeline.steps`\n",
    "\n",
    "            for train, test in TimeSeriesSplit(number_of_splits).split(X,y):\n",
    "                my_pipeline.fit(X.iloc[train],y.iloc[train])\n",
    "                predictions = my_pipeline.predict(X.iloc[test])\n",
    "                truth = y.iloc[test]\n",
    "\n",
    "                # Calculate and save the metrics for this fold\n",
    "                for name, func, scores in metrics:\n",
    "                    score = func(truth, predictions)\n",
    "                    scores.append(score)\n",
    "            mlflow . log_param (f\"pipeline_{model_tuple[0]}\", my_pipeline)\n",
    "            # Log a summary of the metrics\n",
    "            for name, _, scores in metrics:\n",
    "                    # NOTE: Here we just log the mean of the scores. \n",
    "                    # Are there other summarizations that could be interesting?\n",
    "                    mean_score = sum(scores)/number_of_splits\n",
    "                    #mlflow . log_param (f\"mean_score_{name}_{model_tuple[0]}\", mean_score)\n",
    "                    print(f\"{model_tuple[0]} {name}\", mean_score)\n",
    "                    mlflow.log_metric(f\"mean_{name}_{name}_{model_tuple[0]}\", mean_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a8f2d37e2876b7fcbffdd8f25d333c8bfb8883be744558345645bedf06f40271"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
